---
source: Rmd
title: "Linear regression with one continuous and one categorical explanatory variable"
objectives:
  - Explore the relationship between a continuous dependent variable and two explanatory variables, one continuous and one categorical, using ggplot2. 
  - Fit a linear regression model with one continuous and one categorical explanatory variable using lm(). 
  - Use the jtools package to interpret the model output. 
  - Use the interactions package to visualise the model output.
keypoints:
  - A scatterplot, with points coloured by the levels of a categorical variable, can be used to explore the relationship between two continuous variables and a categorical variable.
  - The categorical variable can be added to the `formula` in `lm()` using a `+`.
  - The model output shows separate intercepts for the levels of the categorical variable. The slope across the levels of the categorical variable is held constant. 
  - Parallel lines can be added to the exploratory scatterplot to visualise the linear regression model. 
questions:
  - How can the relationship between three variables, two of which are continuous and one of which is categorical, be visualised in R?
  - How can a linear regression model be fit to this type of data in R?
  - How are the model parameters obtained from R and interpreted?
  - How is the linear regression model visualised in R?
teaching: 10
execises: 10
---

```{r, include=FALSE}
source("../bin/chunk-options.R")
source("../bin/obtain_data.R")
knitr_fig_path("01-")

library(dplyr)
library(ggplot2)
library(jtools)
library(interactions)
```

In this episode we will learn to fit a linear regression model when we have two explanatory variables: one continuous and one categorical. Before we fit the model, we can explore the relationship between our variables graphically. We are asking the question: does the relationship between the continuous explanatory variable and the response variable differ between the levels of the categorical variable?

Let us take response variable `BMI`, the continuous explanatory variable `Weight` and the categorical explanatory variable `Sex` as an example. The code below subsets our data for individuals who are older than 17 years with `filter()`. The plotting is then initiated using `ggplot()`. Inside `aes()`, we select the response variable with `y = BMI`, the continuous explanatory variable with `x = Weight` and the categorical explanatory variable with `colour = Sex`. As a consequence of the final argument, the points produced by `geom_point()` are coloured by `Sex`. Finally, we include opacity using `alpha = 0.4`, which allows us to distinguish areas dense in points from sparser areas. Note that RStudio returns the error "Removed 320 rows containing missing values (geom_point)." - this reflects that 320 participants had missing BMI and/or Weight data. 

The plot suggests that on average, participants of the female sex have a higher `BMI` than participants of the male sex, for any particular value of `Weight`. We might therefore want to account for this in our model by having *separate intercepts* for the levels of `Sex`.

```{r BMI_Weight_Sex exploratory plot, warning = FALSE}
dat %>%
  filter(Age > 17) %>%
  ggplot(aes(x = Weight, y = BMI, colour = Sex)) +
  geom_point(alpha = 0.4) 
```

> ## Exercise  
> You have been asked to model the relationship between `Height`
> and `Weight` in the NHANES data, using data from participants
> with a `Black` or `Mexican` race. Use the ggplot2
> package to create an exploratory plot, ensuring that:
> 1. The data is filtered for participants over the age of 17, with a 
> Black or Mexican race. Race is described by the `Race1` variable.  
> 2. Weight (`Weight`) on the y-axis and Height (`Height`) on the x-axis, from the NHANES data.  
> 3. This data shown as a scatterplot, with opacity and points coloured by race.
>
> > ## Solution
> > 
> > ```{r weight vs height by race plot, warning = FALSE}
> > dat %>%
> >   filter(Race1 %in% c("Black", "Mexican"),
> >          Age > 17) %>%
> >   ggplot(aes(x = Height, y = Weight, colour = Race1)) +
> >   geom_point(alpha = 0.4)
> > ```
> {: .solution}
{: .challenge}

We fit the model using `lm()`. With `formula = BMI ~ Weight + Sex` we specify that our model has two explanatory variables, `Weight` and `Sex`. 

```{r fit BMI_Weight_Sex}
BMI_Weight_Sex <- dat %>%
  filter(Age > 17) %>%
  lm(formula = BMI ~ Weight + Sex)
```

The linear model equation associated with this model has the general form

$$E(y) = \beta_0 + \beta_1 \times x_1 + \beta_2 \times x_2$$.

Notice that we now have the additional parameters, $\beta_2$ and $x_2$, in comparison to the simple linear regression model equation. In the context of our model, $\beta_1$ is the parameter for the effect of `Weight` and $\beta_2$ is the parameter for the effect of `Sex`. Recall from the simple linear regression lesson that a categorical variable has a baseline level in R. The parameter associated with the categorical variable then estimates the difference in the outcome variable in a group different from the baseline. Since "f" precedes "m" in the alphabet, R takes `female` as the baseline level. Therefore, $\beta_2$ estimates the difference in BMI between males and females, given a particular value for `Weight`. $\beta_2$ is only included when $x_2 = 1$, i.e. when the `Sex` of a participant is `male`. This results in separate intercepts for the levels of `Sex`: the intercept for `females` is given by $\beta_0$ and the intercept for `males` is given by $\beta_0 + \beta_2$. In this model, the effect of `Weight` is given by $\beta_1$, irrespective of the `Sex` of a participant. This results in equal slopes across the levels of `Sex`. 

The model parameters can be obtained using `summ()` from the `jtools` package. We include 95% confidence intervals for the parameter estimates using `confint = TRUE` and three digits past the decimal using `digits = 3`. The intercept when `Sex = female` equals $5.538$ and the intercept when `Sex = male` equals $5.538 - 4.202 = 1.336$. Notice that in this model, the effect of `Weight` is $0.310$, regardless of `Sex`. The model equation can therefore be updated to be:

$$E(\text{BMI}) = 5.538 + 0.310 \times \text{Weight} -4.202 \times x_2,$$  

where $x_2 = 1$ for `Sex = male` and $0$ otherwise. 


```{r summ BMI_Weight_Sex}
summ(BMI_Weight_Sex, confint = TRUE, digits = 3)
```

> ## Exercise  
> 1. Using the `lm()` command, fit a multiple linear regression of Weight
> (`Weight`) as a function of Height (`Height`), grouped by `Black` and `Mexican` race (`Race1`). Name this `lm` object `Weight_Height_Race`.  
> 2. Using the `summ` function from the `jtools` package, answer the following questions:
>   
> A) What Weight does the model predict, on average,
> for an individual, belonging to the baseline level of `Race1`,
> with a `Height` of 0?  
> B) What is R taking as the baseline level of `Race1` and why?  
> C) By how much is `Weight` expected to differ, on average, for
> the alternative level of `Race1`?  
> D) By how much is `Weight` expected to differ, on average, for
> a one-unit difference in `Height`?  
> E) Given these values and the names of the response and explanatory
> variables, how can the general equation $E(y) = \beta_0 + {\beta}_1 
> \times x_1 + {\beta}_2 \times x_2$ be adapted to represent the model? 
>
> > ## Solution
> > 
> > ```{r weight vs height by race model}
> > Weight_Height_Race1 <- dat %>%
> >   filter(Race1 %in% c("Black", "Mexican"),
> >          Age > 17) %>%
> >   lm(formula = Weight ~ Height + Race1)
> > 
> > summ(Weight_Height_Race1, confint = TRUE, digits=3)
> > ```
> > 
> > A) -61.745 cm  
> > B) `Black`, because "b" precedes "m" in the alphabet.  
> > C) On average, individuals from the two races are expected to differ
> > by 3.396 cm.  
> > D) 0.882 cm.  
> > E) $E(\text{Weight}) = -61.745 + 0.882 \times \text{Height} - 3.396 \times \text{RaceMexican}$, where $RaceMexican = 1$ for `Mexican` participants and 
> > $0$ otherwise.
> {: .solution}
{: .challenge}

The model can be visualised using two lines, representing the levels of `Sex`. Rather than using `effect_plot()` from the `jtools` package, we use `interact_plot` from the `interactions` package. We specify the model by its name, the continuous explanatory variable using `pred = Weight` and the categorical explanatory variable using `modx = Sex`. We include the data points using `plot.points = TRUE` and introduce opacity into the data points using `point.alpha = 0.4`. 

Note that R returns the warning "Weight and Sex are not included in an interaction with one another in the model." - we will learn what interactions are and when they might be appropriate in the next episode. In this scenario we can safely ignore the warning.

```{r effect_plot BMI_Weight_Sex, warning = FALSE}
interact_plot(BMI_Weight_Sex, pred = Weight, modx = Sex,
              plot.points = TRUE, point.alpha = 0.4)
```


> ## Exercise  
> To help others interpret the `Weight_Height_Race1` model, produce a figure. 
> Make this figure using the `interactions` package.
>
> > ## Solution
> > ```{r plot Weight_Height_Race1, warning = FALSE}
> > interact_plot(Weight_Height_Race1, pred = Height, modx = Race1,
> >               plot.points = TRUE, point.alpha = 0.4)
> > ```
> {: .solution}
{: .challenge}



